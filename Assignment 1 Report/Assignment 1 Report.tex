\documentclass[12pt, letterpaper]{article}
\usepackage{graphicx}
\graphicspath{ {Images/} }

\begin{document}
Assignment 1 Local Search Report

By Brandon Young and Ruicheng Wu

\bigskip

\paragraph{Task 1. Puzzle Representation} \mbox{}\\

Here are a couple of images of the GUI we used for this assignment. This first image shows all of the options available as well as where the parameters are entered in:

\includegraphics[width=\linewidth]{"Task 1/Sample GUI 4"}

The image below was obtained after generating a puzzle and running hill climb (number of iterations = 50). The (x:y) format shows the k values at various iterations where x is the iteration number and y is the k value found at that iteration. The GUI also shows the time it took to run basic hill climb, the best K, the puzzle found (matrix on the left) and the evaluated version (matrix on the right).

\includegraphics[width=\linewidth]{"Task 1/Sample GUI 3"}

\pagebreak

\paragraph{Task 2. Puzzle Evaluation} \mbox{}\\

\quad The puzzle is on the left, while the BFS output is on the right. The following shows 2 puzzles for each possible size, one that is solvable and one that is unsolvable

\medskip
\quad 1. 5x5 (Solvable):
	
\includegraphics[width=3in]{"Task 2/5x5 Puzzle (Solvable)"}

\bigskip
\quad 2. 5x5 (Unsolvable):

\includegraphics[width=3in]{"Task 2/5x5 Puzzle (Unsolvable)"}

\bigskip
\quad 3. 7x7 (Solvable):

\includegraphics[width=4in, keepaspectratio]{"Task 2/7x7 Puzzle (Solvable)"}

\bigskip	
\quad 4. 7x7 (Unsolvable):

\includegraphics[width=4in, keepaspectratio]{"Task 2/7x7 Puzzle (Unsolvable)"}

\bigskip	
\quad 5. 9x9 (Solvable):
	
\includegraphics[width=4in, height=15cm, keepaspectratio]{"Task 2/9x9 Puzzle (Solvable)"}
	
\bigskip
\quad 6. 9x9 (Unsolvable):
	
\includegraphics[width=4in, height=15cm, keepaspectratio]{"Task 2/9x9 Puzzle (Unsolvable)"}


\bigskip
\quad 7. 11x11 (Solvable):
	
\includegraphics[width=5in, keepaspectratio]{"Task 2/11x11 Puzzle (Solvable)"}

\bigskip
\quad 8. 11x11 (Unsolvable):

\includegraphics[width=5in, keepaspectratio]{"Task 2/11x11 Puzzle (Unsolvable)"}

\pagebreak
\paragraph{Task 3. Basic Hill Climb} \mbox{}\\

To get the following plots we ran hill climb 50 times for 3000 iterations and at every 100th iteration we took the K value at that interval. Then we averaged the K values at each interval to get the data for the following scatterplots:

\includegraphics[width=\linewidth]{"Task 3/5x5 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 3/7x7 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 3/9x9 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 3/11x11 Scatterplot"}

\pagebreak
\paragraph{Task 4. Hill Climbing with Random Restarts} \mbox{}\\

For hill climbing with random restarts, using 600 iterations and 5 restarts, the best individual hill climb was picked and its K values were recorded at every 30 iterations:

\includegraphics[width=\linewidth]{"Task 4/5x5 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 4/7x7 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 4/9x9 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 4/11x11 Scatterplot"}

\bigskip

Compared to basic hill climbing, hill climbing with restarts appears to do worse. On the 5x5 plots, for example, restarts only reaches K = 11 at most, but basic hill climb reaches K = 12.

For the number of restarts, more than 2 restarts are preferred, to differentiate from basic hill climb. Yet the number of restarts should not be too high, or the hill climb process will be too short to be effective compared to basic hill climb. So 5 restarts was chosen for the plots above.

\pagebreak
\paragraph{Task 5. Hill Climbing with Random Walking} \mbox{}\\

For hill climbing with random walking, p = 0.01, where p is the probability of allowing downhill movement. A similar process with basic hill climbing was used to obtain the scatterplots below:

\includegraphics[width=\linewidth]{"Task 5/5x5 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 5/7x7 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 5/9x9 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 5/11x11 Scatterplot"}

\bigskip

Random walk does appear to work, however, the dips caused by downhill movement can be too severe to recover from. This is why p was set to 0.01, but it looks like it could be set even lower to retain the effectiveness of basic hill climbing. 

Compared to plain hill climbing and climbing with restarts, random walk performs much worse, reaching a high of about K = 8.5 for 5x5 puzzles while the other 2 methods surpassed 10. However, this may be caused by the averaging of data points, since at some points in the plots, there can be a jump in K values (such as from iterations 800 to 900 on the 9x9 plot).

\pagebreak
\paragraph{Task 6. Simulated Annealing} \mbox{}\\

The parameters used for simulated annealing were: T (initial temperature)= 1000, decay rate = 0.99 with 3000 iterations and every 100th iteration being recorded. The decay rate was picked so that the temperature would not decay too quickly or the results would end up the same as random walk's.

\includegraphics[width=\linewidth]{"Task 6/5x5 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 6/7x7 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 6/9x9 Scatterplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 6/11x11 Scatterplot"}

\bigskip

Compared to random walk, simulated annealing (SA) is much more successful, reaching a max K of 12 at the 3000th iteration compared to random walk's 8.5. Simulated annealing achieved maximum K values of about 12, 30, 46 and 37 for 5x5, 7x7, 9x9 and 11x11 puzzles respectively. In comparison, in the same total number of iterations, hill climbing with random restarts obtained K values of about 11, 22, 21 and 18. Simulated annealing performs objectively better. 

However, compared to basic hill climbing, simulated annealing performs about the same, with the exception of 11x11 puzzles where simulated annealing has a lower maximum K value. This may be caused by the randomness due to the probability of downhill movement, but it shows that basic hill climbing is the most reliable out of the four methods.

\pagebreak
\paragraph{Task 7. Genetic Algorithms} \mbox{}\\

In order to run the genetic algorithm (GA), you need populations size and mutating probability, as seen below. Iterations is optional (by default set to 1) and computation time was used to collect statistics on runtime VS K values. By default, the population size is $5$, the mutation probability is $0.5$ and the number of iterations is $1$. Note: there are parameters like selection probability that we generates inside of the function.\\

\includegraphics[scale=0.6]{"Task 7/GA-section"}
\includegraphics[scale=0.6]{"Task 7/Puzzle-size"}\\

In our implementation of GA, the final optimized puzzle is the candidate with the highest fitness value, K, after all of the iterations are done. For each iteration, multiple puzzles (determined by population size) are randomly created and placed in a set. In addition, if any puzzles are invalid (have a negative K value), then another puzzle is created, in order to start with a better population. Then each individual puzzle is evaluated with the fitness function. We select a decent amount of two puzzle groups according to each individuals' fitness value (some puzzles may not be chosen at all while some may be chosen repeatedly). After selection, we randomly choose one row of puzzles in same group and do this for every group. Then process to cross-over,that is swap Part A of first puzzle with Part A of second puzzle in same group. So now each group should have $PartA-PuzzleOne-PartB-PuzzleTwo$ $PartA-PuzzleTwo-PartB-PuzzleOne$ like structure. The last step is mutation, with the corresponding mutating probability, each individual puzzle will have a chance to mutate a randomly selected row (or not mutate at all).

\bigskip
\noindent Steps:

1, Generation: randomly generate population size $p$ puzzles, store in a 3D Array, where each 2D array represents a puzzle.\\

2. Fitness Evaluation and Selection: process each puzzle with fitness function and store corresponding k into an array. Will calculate the total k sum and the proportion of each puzzle, for instance, a k group : $[4,3,2,1]$, the puzzle with ${k=4}$ will be 40 percent and puzzle with $k=1$ will be 10 percent. These probability will be mapping along one line with range $[0,1)$, in this case,$[0,0.4),[0.4,0.7),[0.7,0.9),[0.9,1)$. After storing and mapping k, we use $Math.random()$ to determine the selection. In $Javascript$, $Math.random()$ will generate a number randomly between 0(inclusive),1(exclusive).We check which interval it is located.Do this twice for each selection iteration(an inner loop).According to the combinatorial theory, we decide to run this selection loop until we have either $C(p,2)$ group with no duplicate matrix or this loop has iterated more than population size p(In case the loop stuck when some puzzles with extreme high k being choosing repeatedly or just the order being swapped like $A-B$ and $B-A$).After this loop, we should have a descent amount of group with two puzzles each.\\

(Note : in order to keep a good start, we sort out any puzzle with negative value.)\\

3. Random Pick and Crossing-Over: for each group , use an advanced random number trick to pick a row to cut off and cross over, each group will only need one random number bases their total row numbers. We didn't choose to pick column because it is easier to get entire row than column when we coded(Or if you visualize the $2d$ array as column-row,that is another story).When cross-over, PartA of 1st puzzle will be joined with PartB of 2nd puzzle to make a new puzzle with exact same size as before.And the rest part joined together. Apply this operation to each group, a group of new crossover puzzle is presenting.\\

4. Mutating and Find Best K: Going through all operations before, in our code,randomly pick a row for each puzzle first, then we use random trick again to decide if their chosen rows are going to be mutated or not(We choose to mutate one row instead of one cell).After mutating has done, we present all these puzzles to being evaluated again and capture the puzzle with highest K and draw it and its visualizing matrix on the screen presenting with other data.\\

5. Grand Outer Loop and Harvesting: All operations above are just one run of GA. So we take iteration number to go through GA and harvest the puzzle with highest value K and present it and its visualizing matrix on the screen.\\

\bigskip
\paragraph{Computation Time Comparison} \mbox{}\\

As far as the computation time goes, our genetic algorithm appears to perform the best overall compared to all other methods. 

The parameters were used:

\begin{itemize}
	\item Basic Hill Climb: 1000 iterations
	\item Random Restart: 40 iterations, 25 restarts
	\item Random Walk: 1000 iterations, p = 0.5
	\item Simulated Annealing: 1000 iterations, T = 1000, decay rate = 0.5
	\item Genetic Algorithm: population size = 50, iteration = 20, mutation probability = 0.5
\end{itemize}

The plots found are listed below with time (in ms) on the x axis and average K value on the y axis.

\includegraphics[width=\linewidth]{"Task 7/5x5 Timeplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 7/7x7 Timeplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 7/9x9 Timeplot"}

\bigskip

\includegraphics[width=\linewidth]{"Task 7/11x11 Timeplot"}

\pagebreak
\paragraph{Task 8. Hardest Puzzle} \mbox{}\\

To create the hardest puzzle, originally we used basic hill climbing for its reliability and got an 11x11 puzzle with K = 103 and got stuck for over 30000 runs. Then we tried simulated annealing, using t=10 and decay rate=0.5 with iteration 2000 every run, which ran much faster and produced a puzzle whose K is 109 in hundreds runs.

\includegraphics[width=\linewidth]{"Task 8/Hardest Puzzle"}

\end{document}